# ğŸ’¬ DocuChat - Real-Time RAG System

A sophisticated Retrieval-Augmented Generation (RAG) system that transforms any document into an intelligent conversational partner. Upload your documents and have natural conversations to extract insights, summaries, and specific information with precision.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ” The Problem

Traditional Large Language Models (LLMs) struggle with:
- Processing large documents effectively
- Maintaining context across extensive content
- Providing source citations for their responses
- Handling document-specific queries with precision

## ğŸ’¡ The Solution

Our RAG system addresses these challenges by:
- **Real-time document processing** with intelligent chunking
- **Vector embeddings** for semantic understanding
- **Contextual conversations** with memory retention
- **Source citation** showing exactly where answers originate
- **ChatGPT-like interface** for intuitive user experience

## âš¡ Key Features

### ğŸš€ Core Functionality
- âœ… **Multi-format Support** - PDF, TXT, and DOCX files
- âœ… **Real-time Processing** - Instant document analysis and embedding creation
- âœ… **Intelligent Chunking** - Optimized text segmentation for better retrieval
- âœ… **Semantic Search** - Vector-based similarity matching
- âœ… **Conversation Memory** - Maintains context throughout chat sessions
- âœ… **Source References** - Direct citations from original document sections

### ğŸ¨ User Experience
- âœ… **Modern UI** - Clean, responsive ChatGPT-inspired interface
- âœ… **Progress Tracking** - Real-time processing status updates
- âœ… **File Management** - Easy upload with size and format validation
- âœ… **Interactive Chat** - Natural conversation flow with the document
- âœ… **Mobile Responsive** - Works seamlessly across devices

## ğŸ› ï¸ Tech Stack

### Backend & AI
- **Framework:** LangChain for RAG pipeline orchestration
- **LLM:** Google Gemini 1.5 Pro for intelligent response generation
- **Embeddings:** HuggingFace all-MiniLM-L6-v2 (384-dimensional vectors)
- **Vector Database:** ChromaDB with MMR (Maximal Marginal Relevance) retrieval
- **Document Processing:** PyPDFLoader, RecursiveCharacterTextSplitter

### Frontend & UI
- **Web Framework:** Streamlit for rapid prototyping and deployment
- **Styling:** Custom CSS for modern, responsive design
- **State Management:** Streamlit session state for conversation history
- **UI Components:** File uploaders, progress bars, chat interface

### Memory & Performance
- **Conversation Memory:** ConversationBufferMemory for chat history
- **Chunking Strategy:** 1000 characters with 200 character overlap
- **Retrieval:** Top-k similarity search with source tracking
- **Processing:** Async document handling with progress indicators

## ğŸ“ Project Structure

```
Real_Time_Rag/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ document_processor.py  # Document loading and chunking logic
â”œâ”€â”€ chatbot_engine.py     # Conversation and response generation
â”œâ”€â”€ utils.py              # Utility functions and session management
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Google API key for Gemini LLM
- Virtual environment (recommended)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Abd756/DocuChat.git
   cd DocuChat
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   # Create .env file or set environment variable
   export GOOGLE_API_KEY="your-gemini-api-key"
   
   # On Windows PowerShell:
   $env:GOOGLE_API_KEY="your-gemini-api-key"
   ```

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

6. **Open your browser**
   Navigate to `http://localhost:8501`

## ğŸ“ Usage Examples

### Basic Document Upload
1. Upload a PDF, TXT, or DOCX file (up to 200MB)
2. Wait for processing and embedding creation
3. Start asking questions about your document

### Sample Queries
```
ğŸ“‹ "Summarize this document in 3 key points"
ğŸ” "What are the main findings in chapter 2?"
ğŸ’¡ "Explain the methodology used in this research"
ğŸ“Š "What are the conclusions and recommendations?"
ğŸ¯ "Find information about [specific topic]"
```

### Advanced Features
- **Source Citations:** Click "View Sources" to see exact document references
- **Conversation History:** Previous context is maintained throughout the session
- **New Sessions:** Use the "New" button to start fresh with a different document

## ğŸ¯ Use Cases

### Professional Applications
- **Research Analysis** - Quickly extract insights from academic papers
- **Legal Document Review** - Find specific clauses and information
- **Business Intelligence** - Analyze reports and strategic documents
- **Medical Research** - Navigate through clinical studies and findings

### Educational Use
- **Study Assistant** - Get explanations from textbooks and papers
- **Literature Review** - Summarize and compare multiple sources
- **Thesis Research** - Extract relevant information efficiently

## ğŸ”§ Configuration

### Document Processing Settings
```python
# In document_processor.py
chunk_size = 1000        # Characters per chunk
chunk_overlap = 200      # Overlap between chunks
top_k = 10              # Number of relevant chunks to retrieve
```

### Model Configuration
```python
# Embedding model: all-MiniLM-L6-v2
# Vector dimensions: 384
# Similarity metric: Cosine similarity
# Retrieval strategy: MMR (Maximal Marginal Relevance)
```

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Format code
black app.py document_processor.py chatbot_engine.py utils.py
```

## ğŸ“Š Performance Metrics

- **Processing Speed:** ~2-3 seconds per MB of document
- **Embedding Generation:** ~1 second per 1000 characters
- **Query Response Time:** ~2-4 seconds depending on document size
- **Supported File Size:** Up to 200MB per document
- **Memory Usage:** Optimized for documents up to 10,000 pages

## ğŸš€ Deployment

### Local Deployment
```bash
streamlit run app.py --server.port 8501
```

### Cloud Deployment Options
- **Streamlit Cloud:** Direct GitHub integration
- **Heroku:** Container-based deployment
- **Docker:** Containerized deployment
- **AWS/GCP/Azure:** Cloud platform deployment

### Docker Deployment
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.address", "0.0.0.0"]
```

## ğŸ”’ Security & Privacy

- **Local Processing:** Documents are processed locally and not stored permanently
- **API Security:** Secure API key management for external services
- **Data Privacy:** No document content is logged or persisted
- **Memory Management:** Automatic cleanup of temporary files

## ğŸ› Troubleshooting

### Common Issues

**1. API Key Error**
```bash
Error: Google API key not found
Solution: Set GOOGLE_API_KEY environment variable
```

**2. Memory Issues with Large Files**
```bash
Error: Out of memory
Solution: Reduce chunk_size or process smaller documents
```

**3. Slow Processing**
```bash
Issue: Document taking too long to process
Solution: Check file size and internet connection for API calls
```

## ğŸ“ˆ Future Enhancements

- [ ] **Multi-document Chat** - Conversation across multiple documents
- [ ] **Advanced Search** - Filters and advanced query options
- [ ] **Export Features** - Save conversations and summaries
- [ ] **Collaborative Features** - Share documents and conversations
- [ ] **API Integration** - REST API for external applications
- [ ] **Multi-language Support** - Process documents in various languages

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangChain** for the powerful RAG framework
- **Streamlit** for the intuitive web interface
- **HuggingFace** for the embedding models
- **Google** for the Gemini LLM API
- **ChromaDB** for efficient vector storage

## ğŸ“ Contact & Support

- **GitHub Issues:** [Report bugs or request features](https://github.com/Abd756/DocuChat/issues)
- **LinkedIn:** [Connect with the developer](https://linkedin.com/in/yourprofile)
- **Email:** your.email@example.com

---

### ğŸŒŸ Star this repository if you found it helpful!

**Made with â¤ï¸ by [Your Name]**

*Transform your documents into intelligent conversations today!*
